{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f3c6eb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'coordinates'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m writer\u001b[38;5;241m.\u001b[39mwriterow([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLatitude\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLongitude\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tweet \u001b[38;5;129;01min\u001b[39;00m english_tweets:\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtweet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoordinates\u001b[49m:\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;66;03m# Write the tweet text, latitude, and longitude to the CSV file\u001b[39;00m\n\u001b[1;32m     33\u001b[0m         writer\u001b[38;5;241m.\u001b[39mwriterow([tweet\u001b[38;5;241m.\u001b[39mcoordinates[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoordinates\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m1\u001b[39m], tweet\u001b[38;5;241m.\u001b[39mcoordinates[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoordinates\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m],tweet\u001b[38;5;241m.\u001b[39mtext])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'coordinates'"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "\n",
    "# Replace the values in the following lines with your own Twitter API keys\n",
    "api_key = \"ufmmiP6WPrf88KFWBucUYqyqj\"\n",
    "api_secret = \"VC5lt1Wa6Y4TDsMByVSzRe5iB36XXNMdFrD99yibpTKt4rHtXS\"\n",
    "access_token = \"1483027022645706754-4JCnTuUQ8FfUMBS8MOre8cufJBK2O6\"\n",
    "access_token_secret = \"5y0pofXx8zwSNJwCWaPFRK04KYli2E3MAsP29lpsB2tZO\"\n",
    "\n",
    "# Authenticate to Twitter API\n",
    "auth = tweepy.OAuthHandler(api_key, api_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "# Create API object\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "# Search for tweets in the specified location\n",
    "tweets = tweepy.Cursor(api.search_tweets,q=\"\",\n",
    "              geocode=\"41.0082,28.9784,1km\",\n",
    "              lang=\"en\",\n",
    "              tweet_mode='extended').items(1000)\n",
    "\n",
    "# Extract only the text of tweets in English language\n",
    "english_tweets = [tweet.full_text for tweet in tweets if tweet.lang == \"en\"]\n",
    "\n",
    "# Write the extracted tweets to a CSV file\n",
    "with open(\"tweets_english.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Latitude\", \"Longitude\",\"Text\"])\n",
    "    for tweet in english_tweets:\n",
    "        if tweet.coordinates:\n",
    "            # Write the tweet text, latitude, and longitude to the CSV file\n",
    "            writer.writerow([tweet.coordinates[\"coordinates\"][1], tweet.coordinates[\"coordinates\"][0],tweet.text])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65cc82b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "\n",
    "# Replace the values in the following lines with your own Twitter API keys\n",
    "api_key = \"ufmmiP6WPrf88KFWBucUYqyqj\"\n",
    "api_secret = \"VC5lt1Wa6Y4TDsMByVSzRe5iB36XXNMdFrD99yibpTKt4rHtXS\"\n",
    "access_token = \"1483027022645706754-4JCnTuUQ8FfUMBS8MOre8cufJBK2O6\"\n",
    "access_token_secret = \"5y0pofXx8zwSNJwCWaPFRK04KYli2E3MAsP29lpsB2tZO\"\n",
    "\n",
    "# Authenticate to Twitter API\n",
    "auth = tweepy.OAuthHandler(api_key, api_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "# Create API object\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "# Search for tweets in the specified location\n",
    "tweets = tweepy.Cursor(api.search_tweets,q=\"\",\n",
    "              geocode=\"41.0082,28.9784,1km\",\n",
    "              lang=\"en\",\n",
    "              tweet_mode='extended').items(10000)\n",
    "\n",
    "# Extract the text and coordinates of tweets in English language\n",
    "english_tweets = [(tweet.full_text, tweet.coordinates) for tweet in tweets if tweet.lang == \"en\" and tweet.coordinates is not None]\n",
    "\n",
    "# Write the extracted tweets, latitude, and longitude to a CSV file\n",
    "with open(\"tweets_english.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Latitude\", \"Longitude\",\"Tweet\"])\n",
    "    for tweet, coord in english_tweets:\n",
    "        lat, lon = coord[\"coordinates\"]\n",
    "        writer.writerow([lat, lon, tweet])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ce311a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "# The input CSV file\n",
    "input_file = \"tweets_english.csv\"\n",
    "\n",
    "# The output CSV file\n",
    "output_file = \"output_english.csv\"\n",
    "\n",
    "# Regular expression pattern to match URLs\n",
    "url_pattern = re.compile(r\"(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?\")\n",
    "\n",
    "# Read the input CSV file\n",
    "with open(input_file, \"r\") as f_input:\n",
    "    reader = csv.reader(f_input)\n",
    "    header = next(reader)\n",
    "    text_column_index = header.index(\"Tweet\")\n",
    "    data = [row for row in reader]\n",
    "\n",
    "# Split the text and URLs into separate columns\n",
    "rows = []\n",
    "for row in data:\n",
    "    text = row[text_column_index]\n",
    "    urls = re.findall(url_pattern, text)\n",
    "    at_index = text.find(\"@\")\n",
    "    if at_index != -1:\n",
    "        text_before_at = text[:at_index].strip()\n",
    "        text_after_at = text[at_index:].strip()\n",
    "    else:\n",
    "        text_before_at = text\n",
    "        text_after_at = \"\"\n",
    "    for url in urls:\n",
    "        text_before_at = text_before_at.replace(url[0] + \"://\" + url[1] + url[2], \"\")\n",
    "        text_before_at = re.sub(r'[^\\w\\s]', '', text_before_at) # remove symbols\n",
    "        text_before_at = re.sub(r'#\\w+', '', text_before_at) # remove hashtags\n",
    "        rows.append(row[:text_column_index] + [text_before_at, text_after_at] + [url[0] + \"://\" + url[1] + url[2]] + row[text_column_index+1:])\n",
    "\n",
    "# Write the output CSV file\n",
    "with open(output_file, \"w\", newline=\"\") as f_output:\n",
    "    writer = csv.writer(f_output)\n",
    "    writer.writerow(header + [\"Text after @\", \"URL\"])\n",
    "    writer.writerows(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef31724",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
